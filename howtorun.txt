1шаг python scripts/01_build_label.py --input /Users/a08406776/Documents/project/data/raw/Data_Carrard_2022_MedTeach.csv --t 27
//
2шаг python scripts/02_preprocess_split.py
//
получил слишком хорошие результаты -> удалили во 2м файле
numeric_expected = {
        "age","year","stud_h","psyt","jspe","qcae_cog","qcae_aff",
        "amsp","erec_mean","cesd","stai_t"
    }

//

3шаг python scripts/03_train_logreg.py
запускать из project
// 

заменили

03_train_logreg.py

вывод

(base) a08406776@iMac-4 project % python scripts/03_train_logreg.py
[INFO] Prevalence  train=0.0419  val=0.0376  test=0.0451  (AP бейзлайн ~= prevalence)
[INFO] Best params: {'C': 0.1, 'penalty': 'l1'} | CV(AP)=0.3902

=== Logistic Regression (logreg) class_weight=balanced solver=liblinear ===
[TRAIN] PR-AUC=0.3355 | ROC-AUC=0.8786 | F1=0.1704 | Recall@0.35=0.8846 | Brier=0.1525
[VAL  ] PR-AUC=0.1811 | ROC-AUC=0.8516 | F1=0.1515 | Recall@0.35=1.0000 | Brier=0.1871
[TEST ] PR-AUC=0.0958 | ROC-AUC=0.6352 | F1=0.1053 | Recall@0.35=0.5000 | Brier=0.1483

--- Majority baseline (always 0) ---
[VAL  ] PR-AUC=0.0376 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0376
[TEST ] PR-AUC=0.0451 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0451

или ...................................................................................................................
(base) a08406776@iMac-4 project % python scripts/03_train_logreg.py --penalty l2 --solver liblinear
[INFO] Prevalence  train=0.0419  val=0.0376  test=0.0451  (AP бейзлайн ~= prevalence)
[INFO] Best params: {'C': 0.5, 'penalty': 'l2'} | CV(AP)=0.3803

=== Logistic Regression (logreg) class_weight=balanced solver=liblinear ===
[TRAIN] PR-AUC=0.3726 | ROC-AUC=0.9120 | F1=0.2150 | Recall@0.35=0.8846 | Brier=0.1284
[VAL  ] PR-AUC=0.1079 | ROC-AUC=0.7812 | F1=0.1379 | Recall@0.35=0.8000 | Brier=0.1775
[TEST ] PR-AUC=0.1682 | ROC-AUC=0.6798 | F1=0.1333 | Recall@0.35=0.5000 | Brier=0.1424

--- Majority baseline (always 0) ---
[VAL  ] PR-AUC=0.0376 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0376
[TEST ] PR-AUC=0.0451 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0451



//

обновил xgboost
(base) a08406776@iMac-4 project % pip install -U xgboost
Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (3.0.4)
Collecting xgboost
  Downloading xgboost-3.0.5-py3-none-macosx_10_15_x86_64.whl.metadata (2.1 kB)
Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)
Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)
Downloading xgboost-3.0.5-py3-none-macosx_10_15_x86_64.whl (2.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 15.9 MB/s eta 0:00:00
Installing collected packages: xgboost
  Attempting uninstall: xgboost
    Found existing installation: xgboost 3.0.4
    Uninstalling xgboost-3.0.4:
      Successfully uninstalled xgboost-3.0.4
Successfully installed xgboost-3.0.5
(base) a08406776@iMac-4 project % 

обновили 4й файл

запуск
python scripts/04_train_model.py --model rf
python scripts/04_train_model.py --model xgb --save_probas
python scripts/04_train_model.py --model mlp

выводы

=== MLP ===
[VAL ] PR-AUC=0.0962 | ROC-AUC=0.7734 | F1=0.1000 | Recall@0.35=0.2000 | Brier=0.0890
[TEST] PR-AUC=0.0688 | ROC-AUC=0.6273 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0663

=== XGB ===
[VAL ] PR-AUC=0.1206 | ROC-AUC=0.8266 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0700
[TEST] PR-AUC=0.1640 | ROC-AUC=0.6535 | F1=0.1818 | Recall@0.35=0.1667 | Brier=0.0503

(base) a08406776@iMac-4 project % python scripts/04_train_model.py --model rf 
[INFO] Prevalence: train=0.0419 val=0.0376 test=0.0451 (AP бейзлайн ~= prevalence)

=== RF ===
[VAL ] PR-AUC=0.1241 | ROC-AUC=0.8328 | F1=0.1000 | Recall@0.35=0.2000 | Brier=0.0635
[TEST] PR-AUC=0.0996 | ROC-AUC=0.5827 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0554

решаем настроить отдельный скрипт для  xgb

создали 05_tune_xgb
вывод

=== Final XGB (from best CV config) ===
[VAL ] PR-AUC=0.1307 | ROC-AUC=0.8516 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0502
[TEST] PR-AUC=0.1009 | ROC-AUC=0.5853 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0507

--- Majority baseline (always 0) ---
[VAL ] PR-AUC=0.0376 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0376
[TEST] PR-AUC=0.0451 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0451

оптимизировали получили при запуске
python scripts/05_tune_xgb.py \\n  --trials 120 --cv_folds 4 --cv_repeats 8 \\n  --agg mean_minus_std --agg_alpha 1.0 \\n  --booster_mode gbtree --spw_mode sqrt --es_rounds 0 \\n  --search_space light --train_on train \\n  --save_model --save_probas

python scripts/05_tune_xgb.py --trials 120 --cv_folds 4 --cv_repeats 8 --agg mean_minus_std --agg_alpha 1.0 --booster_mode gbtree --spw_mode sqrt --es_rounds 0 --search_space light --train_on train --save_model --save_probas

=== Final XGB (best CV config) ===
[VAL ] PR-AUC=0.1106 | ROC-AUC=0.7937 | F1=0.1111 | Recall@0.35=0.2000 | Brier=0.0620
[TEST] PR-AUC=0.2072 | ROC-AUC=0.6181 | F1=0.4000 | Recall@0.35=0.3333 | Brier=0.0481

--- Majority baseline (always 0) ---
[VAL ] PR-AUC=0.0376 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0376
[TEST] PR-AUC=0.0451 | ROC-AUC=0.5000 | F1=0.0000 | Recall@0.35=0.0000 | Brier=0.0451

///

содаем 
06_select_threshold.py
Чтобы довести результат до практического вида 
(и красиво показать в магистерской), давай отдельно и 
честно подберём порог по кросс-валидации на train, 
а потом оценим его на test. Я сделал тебе отдельный скрипт: 
он читает лучший конфиг из xgb_tuning_summary.json, 
строит out-of-fold предсказания на train (Repeated Stratified CV),
оптимизирует порог по Fβ (по умолчанию β=2 для приоритета recall), 
а затем обучает финальную модель и оценивает её на test ровно при найденном пороге.


(base) a08406776@iMac-4 project % python scripts/06_select_threshold.py --beta 1.0 --cv_folds 5 --cv_repeats 5 \
  --train_on train --save_curves
[INFO] OOF PR-AUC on train = 0.1650
[INFO] Best threshold by F1.0 on OOF: thr=0.185, Fβ=0.2651

=== XGB with threshold selected by CV ===
[VAL ] PR-AUC=0.1106 | F1=0.1667 | Prec@0.18=0.1053 | Recall@0.18=0.4000
[TEST] PR-AUC=0.2072 | F1=0.2000 | Prec@0.18=0.1429 | Recall@0.18=0.3333

[OK] Результаты сохранены: artifacts/metrics/xgb_thresholded_eval.json
[OK] PR-кривые сохранены в: artifacts/metrics
(base) a08406776@iMac-4 project % 


\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

все для гипотез и вопросов, 
поменяли 3 4 и 5 скрипты, поменяли 6

запускать все с save probas


python scripts/04_train_model.py --model rf  --save_probas --save_model
python scripts/04_train_model.py --model mlp --save_probas --save_model
python scripts/04_train_model.py --model xgb --save_probas --save_model

5й запускать так же


python scripts/06_eval_aggregate.py \
  --processed_dir data/processed \
  --artifacts_dir artifacts \
  --alpha 0.05 --topk 10


  для RQ3 поменяли 2й скрипт
запускать
python scripts/02_preprocess_split.py \
  --input data/processed/_labeled.csv \
  --outdir data/processed \
  --artifacts_dir artifacts \
  --test_size 0.15 --val_size 0.15 --seed 42


поменяли 6й скрипт что для RQ2 
pip install scikit-learn


---------------------

для RQ2 создали файл rq2_feature_importance.py
запускать python scripts/04_rq2_feature_importance.py --processed_dir data/processed --artifacts_dir artifacts \
  --eval_split test --bg_size 200 --max_eval 2000 --bootstrap 300

для RQ3 добавили файл 05_rq3_subgroups
запускать 
python scripts/rq3_subgroups.py --processed_dir data/processed --models_dir artifacts/models --metadata_file artifacts/metadata/subgroups_test.csv --artifacts_dir artifacts --thr 0.35 --n_repeats 15


-----
python scripts/rq1_make_table.py --metrics_dir artifacts/metrics --out_csv artifacts/metrics/rq1_summary.csv


---------------------------------------------------

финалочка

python scripts/01_build_label.py 
python scripts/02_preprocess_split.py
python scripts/03_train_logreg.py

C:\Users\08406776\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\statsmodels\base\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available
  warnings.warn('Inverting hessian failed, no bse or cov_params '

сможем обьяснить

python scripts/04_train_model.py --model rf  --save_probas --save_model
python scripts/04_train_model.py --model mlp --save_probas --save_model
python scripts/04_train_model.py --model xgb --save_probas --save_model
python scripts/05_tune_xgb.py --trials 120 --cv_folds 4 --cv_repeats 8 --agg mean_minus_std --agg_alpha 1.0 --booster_mode gbtree --spw_mode sqrt --es_rounds 0 --search_space light --train_on train --save_model --save_probas


python scripts/rq1_make_table.py --metrics_dir artifacts/metrics --out_csv artifacts/metrics/rq1_summary.csv
вывод metrics/rq1_summary


python scripts/rq2_feature_importance.py --processed_dir data/processed --artifacts_dir artifacts --eval_split test --bg_size 200 --max_eval 2000 --bootstrap 300
вывод 
artifacts/intepretability/rq2_top5_all_models
artifacts/intepretability/rq2_top5_pivot

python scripts/rq3_subgroups.py --processed_dir data/processed --models_dir artifacts/models --metadata_file artifacts/metadata/subgroups_test.csv --artifacts_dir artifacts --thr 0.35 --n_repeats 15

вывод artifacts/intepretability/rq3_subgroups_table

графики
python scripts/06_visualize.py